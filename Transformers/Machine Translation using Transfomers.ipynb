{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import spacy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field,BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translation_utils import translate_sentence,bleu,save_checkpoint,load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import de_core_news_sm\n",
    "nlp_de = de_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp_en = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_german(text):\n",
    "    return [tok.text for tok in nlp_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_german(text):\n",
    "    return [tok.text for tok in nlp_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "german=Field(tokenize=tokenize_german,lower=True,init_token=\"<sos>\",eos_token=\"<eos>\")\n",
    "english=Field(tokenize=tokenize_german,lower=True,init_token=\"<sos>\",eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data,test_data=Multi30k.splits(\n",
    "exts=(\".de\",\".en\"),fields=(german,english)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "german.build_vocab(train_data,max_size=10000,min_freq=2)\n",
    "english.build_vocab(train_data,max_size=10000,min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "    self,\n",
    "    embedding_size,\n",
    "    source_vocab_size,\n",
    "    target_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device\n",
    "    ):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.src_word_embedding=nn.Embedding(source_vocab_size,embedding_size)\n",
    "        self.src_position_embedding=nn.Embedding(max_len,embedding_size)\n",
    "        self.target_word_embedding=nn.Embedding(target_vocab_size,embedding_size)\n",
    "        self.target_position_embedding=nn.Embedding(max_len,embedding_size)\n",
    "        \n",
    "        self.device=device\n",
    "        \n",
    "        self.transformer=nn.Transformer(\n",
    "        embedding_size,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        )\n",
    "        \n",
    "        self.fc_out=nn.Linear(embedding_size,target_vocab_size)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.source_pad_idx=src_pad_idx\n",
    "        \n",
    "    def make_src_mask(self,src):\n",
    "        #src shape = src_len,n  transformer takes opposite fo this n,src_len\n",
    "        src_mask=src.transpose(0,1)==self.source_pad_idx\n",
    "        return src_mask\n",
    "    \n",
    "    \n",
    "    def forward(self,src,target):\n",
    "        src_seq_length,N=src.shape\n",
    "        target_seq_length,N=target.shape\n",
    "        \n",
    "        src_positions=(torch.arange(0,src_seq_length)\n",
    "                       .unsqueeze(1)\n",
    "                       .expand(src_seq_length,N)\n",
    "                       .to(self.device)\n",
    "                      )\n",
    "        \n",
    "        target_positions=(torch.arange(0,target_seq_length)\n",
    "                          .unsqueeze(1)\n",
    "                          .expand(target_seq_length,N)\n",
    "                          .to(self.device)\n",
    "                         )\n",
    "        \n",
    "        \n",
    "        embed_src=self.dropout((self.src_word_embedding(src)+self.src_position_embedding(src_positions)))\n",
    "        \n",
    "        embed_target=self.dropout((self.src_word_embedding(target)+self.target_position_embedding(target_positions)))\n",
    "        \n",
    "        src_padding_mask=self.make_src_mask(src)\n",
    "        target_mask=self.transformer.generate_square_subsequent_mask(target_seq_length).to(self.device)\n",
    "        \n",
    "        out=self.transformer(\n",
    "        embed_src,\n",
    "        embed_target,\n",
    "        src_key_padding_mask=src_padding_mask,\n",
    "        tgt_mask=target_mask\n",
    "        )\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#training phase\n",
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model=False\n",
    "save_model=True\n",
    "\n",
    "\n",
    "num_epochs=5\n",
    "learning_rate=3e-4\n",
    "batch_size=32\n",
    "embedding_size = 512\n",
    "src_vocab_size=len(german.vocab)\n",
    "target_vocab_size=len(english.vocab)\n",
    "\n",
    "num_heads=8\n",
    "num_encoder_layers=3\n",
    "num_decoder_layers=3\n",
    "\n",
    "dropout=0.1\n",
    "\n",
    "max_length=100\n",
    "\n",
    "forward_expansion=4\n",
    "\n",
    "src_pad_idx=english.vocab.stoi[\"<pad>\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard for nice plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=SummaryWriter(\"runs/loss_plot\")\n",
    "step=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator,valid_iterator,test_iterator=BucketIterator.splits(\n",
    "(train_data,valid_data,test_data),\n",
    "batch_size=batch_size,\n",
    "sort_within_batch=True,\n",
    "sort_key=lambda x:len(x.src),\n",
    "device=device,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Transformer(embedding_size,\n",
    "                 src_vocab_size,\n",
    "                 target_vocab_size,\n",
    "                 src_pad_idx,\n",
    "                 num_heads,\n",
    "                 num_encoder_layers,\n",
    "                 num_decoder_layers,\n",
    "                 forward_expansion,\n",
    "                 dropout,\n",
    "                 max_length,\n",
    "                 device,).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "pad_idx=english.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "criterion=nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "if(load_model):\n",
    "    load_checkpoint(torch.load(\"my_checkpoint_pth.tar\"),model,optimizer)\n",
    "    \n",
    "sentence=\"ein pferd geht unter einer br√ºcke neben einem boot.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=10, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5 \n",
      "here\n",
      "Translated example sentence: \n",
      " ['construction', 'short', 'colorful', 'head', 'camera', 'parade', 'camera', 'parade', 'camera', 'construction', 'track', 'head', 'camera', 'parade', 'camera', 'head', 'head', 'large', 'head', 'camera', 'parade', 'camera', 'camera', 'parade', 'camera', 'parade', 'camera', 'track', 'head', 'head', 'head', 'camera', 'parade', 'camera', 'parade', 'camera', 'head', 'camera', 'parade', 'camera', 'parade', 'camera', 'parade', 'camera', 'baby', 'sweater', 'rock', 'path', 'camera', 'colorful', 'track', 'head', 'camera', 'head', 'runs', 'sweater', 'head', 'large', 'sweater', 'vest', 'colorful', 'head', 'camera', 'parade', 'camera', 'parade', 'camera', 'parade', 'camera', 'parade', 'camera', 'parade', 'camera', 'parade', 'racing', 'head', 'camera', 'construction', 'track', 'head', 'camera', 'baby', 'construction', 'camera', 'parade', 'camera', 'sweater', 'vest', 'short', 'sweater', 'parade', 'camera', 'parade', 'camera', 'working', 'tent', 'edge', 'camera', 'sweater', 'vest']\n",
      "Epoch 1/5 \n",
      "here\n",
      "Translated example sentence: \n",
      " ['a', 'horse', 'is', 'walking', 'under', 'a', 'boat', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
      "Epoch 2/5 \n",
      "here\n",
      "Translated example sentence: \n",
      " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
      "Epoch 3/5 \n",
      "here\n",
      "Translated example sentence: \n",
      " ['a', 'horse', 'is', 'walking', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
      "Epoch 4/5 \n",
      "here\n",
      "Translated example sentence: \n",
      " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'bridge', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}/{num_epochs} ')\n",
    "\n",
    "    if(save_model):\n",
    "        checkpoint={\n",
    "            \"state_dict\":model.state_dict(),\n",
    "            \"optimizer\":optimizer.state_dict(),\n",
    "        }\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    translated_sentence=translate_sentence(model,sentence,german,english,device,max_length=100)\n",
    "    \n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target[:-1, :])\n",
    "        \n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    scheduler.step(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Bleu score 26.66\n"
     ]
    }
   ],
   "source": [
    "# running on entire test data takes a while\n",
    "score = bleu(test_data[1:100], model, german, english, device)\n",
    "print(f\"Bleu score {score * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
